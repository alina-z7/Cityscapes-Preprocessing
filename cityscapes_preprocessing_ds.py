# -*- coding: utf-8 -*-
"""cityscapes_preprocessing_ds.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aTUhk_gMhABJTBvEXHQFT6iY9j5TRo8K
"""

!pip3 install cityscapesscripts tensorflow tensorflow_addons numpy

from google.colab import drive
drive.mount('/gdrive', force_remount=True)
drive_root = '/gdrive/My Drive/'

GOOGLE_COLAB_DIR = '/content/'
GT_DIR = GOOGLE_COLAB_DIR + 'gtFine/gtFine/'
IMG_DIR = GOOGLE_COLAB_DIR + 'leftImg/leftImg8bit/'

from cityscapesscripts.download import downloader

session = downloader.login()

downloader.get_available_packages(session=session)

print("Downloading packages...")
package_list = ['leftImg8bit_trainvaltest.zip', 'gtFine_trainvaltest.zip']
downloader.download_packages(session=session, package_names=package_list, destination_path=GOOGLE_COLAB_DIR)

!unzip -q gtFine_trainvaltest.zip -d gtFine
!unzip -q leftImg8bit_trainvaltest.zip -d leftImg

import os
import numpy as np
import tensorflow as tf

# check if the corresponding datasets are in the same path
if not os.path.exists(IMG_DIR) or not os.path.exists(GT_DIR):
    raise FileNotFoundError("Datasets not found. Please extract them correctly.")

output_dir = GOOGLE_COLAB_DIR + 'output/preprocessed_images'
# create output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# preprocess loaded images
def preprocess_images(input_dir, output_dir):
    for root, _, files in os.walk(input_dir):
        for file in files:
            if file.endswith('.png'):
                image_path = os.path.join(root, file)
                output_path = os.path.join(output_dir, file.replace('.png', '.npz'))  # adjust file
                image = tf.io.read_file(image_path)
                image = tf.image.decode_png(image, channels=3)  # adjust channels if needed
                resized_image = tf.image.resize(image, (256, 256)) # resize to 256 x 256 px
                normalized_image = resized_image / 127.5 - 1.0 # normalize from -1 to 1
                np.savez(output_path, images=normalized_image.numpy())

# create an output subdir for leftImg8bit
output_subdir = os.path.join(output_dir, 'leftImg8bit')
os.makedirs(output_subdir, exist_ok=True)

# create an output subdir for gtFine
output_subdir = os.path.join(output_dir, 'gtFine')
os.makedirs(output_subdir, exist_ok=True)

# Preprocess leftImg8bit images
preprocess_images(IMG_DIR, output_subdir)
# Preprocess gtFine images
preprocess_images(GT_DIR, output_subdir)

# need to split into five folds and save to separate npz files (ex: cityscapes-fold1.npz)

def split_in_folds(input_dir, output_dir, num_folds=5):

  subdir_list = ['leftImg8bit', 'gtFine']

  for subdir in subdir_list:

        input_subdir = os.path.join(input_dir, subdir)
        output_subdir = os.path.join(output_dir, subdir)

        for fold in range(num_folds):
            fold_output_dir = os.path.join(output_subdir, f'cityscapes-fold{fold + 1}')
            os.makedirs(fold_output_dir, exist_ok=True)

            fold_paths = []
            for root, _, files in os.walk(input_subdir):
                for file in files:
                    if file.endswith('.npz'):
                        fold_paths.append(os.path.join(root, file))

            fold_size = len(fold_paths) // num_folds
            start_index = fold * fold_size
            end_index = (fold + 1) * fold_size if fold < num_folds - 1 else len(fold_paths)
            fold_paths = fold_paths[start_index:end_index]

            for path in fold_paths:
                filename = os.path.basename(path)
                npz_data = np.load(path)
                np.savez(os.path.join(fold_output_dir, filename), **npz_data)

# Example usage:
split_in_folds(output_dir, output_dir)

# upload train, mdule, data loader, and uvit files

from google.colab import files

uploaded_files = files.upload()

for filename in uploaded_files.keys():
    print(f"File: {filename}, Size: {len(uploaded_files[filename])} bytes")
    with open(filename, 'wb') as f:
        f.write(uploaded_files[filename])

# need to convert fold folders to npz files for data loader

# use the preprocessed leftImg8Bit and gtFine folders to train as cityscapes-fold(&n).npz
import math
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras as kr
import os
from datetime import datetime
import uvit
import modules
import time
import data_loader

def main():
    # Define experiment name and data paths
    exp_name = 'cityscapes-name'
    epochs = 20
    batch_size = 11

    # Load training and testing data
    train_data = data_loader.DataGenerator_PairedReady(OUTPUT_DIR_IMG_DIR, if_train=True)
    test_data = data_loader.DataGenerator_PairedReady(OUTPUT_DIR_GT_DIR, if_train=False)

    # Start time
    start_time = time.time()

    # Initialize UNet-ViT model
    model = uvit.UNetViTModel()
    model.compile()

    # Train the model
    history = model.fit(
        train_data.load(),
        validation_data=test_data.load(),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[modules.GanMonitor(test_data.load())],
    )

    # End time
    end_time = time.time()

    # Training duration
    training_duration = end_time - start_time

    # Print the training time
    print(f"Training time: {training_duration:.2f} seconds")

    # Save the training time to a file
    filename = f'/grand/EVITA/ct-mri/uvit_results/time_train/{exp_name}_train_time.txt'
    with open(filename, "w") as file:
        file.write(f"Training time: {training_duration:.2f} seconds")
        print("Training time saved to", filename)

    # Save the trained model
    model.save_model()

    # Evaluate the model
    model.model_evaluate(test_data.load())

    # Plot losses
    model.plot_losses(history.history)

if __name__ == '__main__':
    main()

while True:
  pass